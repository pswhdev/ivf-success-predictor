{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "*   Fit and evaluate a deep learning classification model to predict if a treatment will be successful or not.\n",
    "\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* outputs/datasets/collection/FertilityTreatmentData.csv.gz\n",
    "* Instructions from the notebooks 02 and 04 on which variables to use for data cleaning and feature engineering.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Train set (features and target)\n",
    "* Test set (features and target)\n",
    "* Data cleaning and Feature Engineering pipeline\n",
    "* Modeling pipeline\n",
    "* Feature importance plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the working directory from its current folder to its parent folder\n",
    "* Access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the parent of the current directory the new current directory:\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"A new current directory has been set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Open dataset\n",
    "df = pd.read_csv(\"outputs/datasets/collection/FertilityTreatmentData.csv.gz\")\n",
    "        \n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: ML Pipeline with all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ML pipeline for Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Transformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class FilterIVFTreatments(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.query(\n",
    "            \"`Main reason for producing embroys storing eggs` == 'Treatment - IVF'\"\n",
    "        )\n",
    "\n",
    "class DropErroneousEntries(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.drop(\n",
    "            X[(X[\"Live birth occurrence\"] == 1) & (X[\"Embryos transferred\"] == 0)].index\n",
    "        )\n",
    "\n",
    "class ConvertToNumeric(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            # Replace '>3' with 4\n",
    "            X[col] = X[col].replace(\">3\", 4)\n",
    "            # Convert to numeric\n",
    "            X[col] = pd.to_numeric(X[col])\n",
    "        return X\n",
    "\n",
    "\n",
    "class ConvertToIntegers(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            # Replace '>3' with 4 and convert to int\n",
    "            X[col] = X[col].replace(\">3\", 4).astype(float).astype(int)\n",
    "        return X\n",
    "\n",
    "\n",
    "class FillSpermSource(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[\"Sperm source\"] = X.apply(self._fill_sperm_source, axis=1)\n",
    "        return X\n",
    "\n",
    "    def _fill_sperm_source(self, row):\n",
    "        if pd.isna(row[\"Sperm source\"]):\n",
    "            if not pd.isna(row[\"Sperm donor age at registration\"]):\n",
    "                return \"Donor\"\n",
    "            else:\n",
    "                return \"Partner\"\n",
    "        return row[\"Sperm source\"]\n",
    "\n",
    "\n",
    "# Convert float values to integers and handle NaN values\n",
    "class ConvertToIntAndReplace999(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        # Fill NaN with -1 and convert to int\n",
    "        X[\"Date of embryo transfer\"] = (\n",
    "            X[\"Date of embryo transfer\"].fillna(-1).astype(int)\n",
    "        )\n",
    "        # Replace 999 with 0\n",
    "        X[\"Date of embryo transfer\"] = X[\"Date of embryo transfer\"].replace(999, 0)\n",
    "        return X\n",
    "\n",
    "\n",
    "# Replace missing values based on the \"Embryos transferred\" column\n",
    "class ReplaceMissingValues(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[\"Date of embryo transfer\"] = X.apply(self._replace_missing, axis=1)\n",
    "        return X\n",
    "\n",
    "    def _replace_missing(self, row):\n",
    "        value = row[\"Date of embryo transfer\"]\n",
    "        if value == -1 and row[\"Embryos transferred\"] == 0:\n",
    "            return \"NT\"\n",
    "        elif value == -1:\n",
    "            return \"Missing\"\n",
    "        return value\n",
    "\n",
    "\n",
    "# Append strings based on the \"Fresh cycle\" and \"Frozen cycle\" values\n",
    "class AppendCycleType(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[\"Date of embryo transfer\"] = X.apply(self._append_cycle_type, axis=1)\n",
    "        return X\n",
    "\n",
    "    def _append_cycle_type(self, row):\n",
    "        value = row[\"Date of embryo transfer\"]\n",
    "        if value not in [\"NT\", \"Missing\"]:\n",
    "            if row[\"Fresh cycle\"] == 1:\n",
    "                value = f\"{value} - fresh\"\n",
    "            elif row[\"Frozen cycle\"] == 1:\n",
    "                value = f\"{value} - frozen\"\n",
    "            else:\n",
    "                value = f\"{value} - Mixed fresh/frozen\"\n",
    "        return value\n",
    "\n",
    "\n",
    "class MicroInjectedEmbryos(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        # Embryos transferred from eggs micro-injected imputation\n",
    "        missing_micro_injected = X[\n",
    "            \"Embryos transferred from eggs micro-injected\"\n",
    "        ].isna()\n",
    "        ICSI = X[\"Specific treatment type\"].str.contains(\"ICSI\")\n",
    "        # Only replace missing values\n",
    "        X.loc[\n",
    "            missing_micro_injected & ICSI,\n",
    "            \"Embryos transferred from eggs micro-injected\",\n",
    "        ] = X.loc[missing_micro_injected & ICSI, \"Embryos transferred\"]\n",
    "        X.loc[\n",
    "            missing_micro_injected & ~ICSI,\n",
    "            \"Embryos transferred from eggs micro-injected\",\n",
    "        ] = 0\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "class DonorAgeImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        # Mapping from donor age ranges to patient/partner age ranges\n",
    "        self.egg_age_map = {\n",
    "            'Between 21 and 25': '18-34',\n",
    "            'Between 26 and 30': '18-34',\n",
    "            'Between 31 and 35': '18-34',\n",
    "            '>35': '38-39',\n",
    "            '<= 20': '18-34'\n",
    "        }\n",
    "        self.sperm_age_map = {\n",
    "            'Between 21 and 25': '18-34',\n",
    "            'Between 26 and 30': '18-34',\n",
    "            'Between 31 and 35': '18-34',\n",
    "            'Between 36 and 40': '38-39',\n",
    "            'Between 41 and 45': '43-44',\n",
    "            '>45': '45-50',\n",
    "            '<= 20': '18-34'\n",
    "        }\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        # Egg donor age imputation\n",
    "        X['Egg donor age at registration'] = X['Egg donor age at registration'].map(self.egg_age_map)\n",
    "        missing_egg_age = (X['Egg donor age at registration'].isna()) & (X['Egg source'] == 'Patient')\n",
    "        X.loc[missing_egg_age, 'Egg donor age at registration'] = X.loc[missing_egg_age, 'Patient age at treatment']\n",
    "        X.rename(columns={'Egg donor age at registration': 'Patient/Egg provider age'}, inplace=True)\n",
    "        \n",
    "        # Sperm donor age imputation\n",
    "        X['Sperm donor age at registration'] = X['Sperm donor age at registration'].map(self.sperm_age_map)\n",
    "        missing_sperm_age = (X['Sperm donor age at registration'].isna()) & (X['Sperm source'] == 'Partner')\n",
    "        X.loc[missing_sperm_age, 'Sperm donor age at registration'] = X.loc[missing_sperm_age, 'Partner age']\n",
    "        X.rename(columns={'Sperm donor age at registration': 'Partner/Sperm provider age'}, inplace=True)\n",
    "\n",
    "        # Drop the \"Partner age\" column\n",
    "        X.drop(columns=['Partner age'], inplace=True)\n",
    "        \n",
    "        # Ensure no duplicate columns\n",
    "        if X.columns.duplicated().any():\n",
    "            raise ValueError(\"Duplicate column names found after transformation\")\n",
    "        \n",
    "        return X\n",
    "\n",
    "\n",
    "class FloatToIntTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.float_vars = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Identify float columns\n",
    "        self.float_vars = X.select_dtypes(include=\"float\").columns.tolist()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for var in self.float_vars:\n",
    "            X[var] = X[var].astype(int)\n",
    "        return X\n",
    "\n",
    "\n",
    "class EFlaggingTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        X[\"Embryos transferred\"] = X.apply(self.append_e, axis=1)\n",
    "        return X\n",
    "\n",
    "    def append_e(self, row):\n",
    "        if (\n",
    "            row[\"Embryos transferred\"] == 1\n",
    "            and row[\"Elective single embryo transfer\"] == 1\n",
    "        ):\n",
    "            return \"1e\"\n",
    "        else:\n",
    "            return row[\"Embryos transferred\"]\n",
    "\n",
    "\n",
    "class TypeOfCycleAppender(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_update):\n",
    "        self.columns_to_update = columns_to_update\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        # Ensure columns have the correct data type to avoid issues\n",
    "        for column in self.columns_to_update:\n",
    "            X[column] = X[column].astype(str)\n",
    "\n",
    "        # Apply transformation for frozen cycle\n",
    "        for column in self.columns_to_update:\n",
    "            X.loc[(X[\"Frozen cycle\"] == 1) & (X[column] == \"0\"), column] = (\n",
    "                \"0 - frozen cycle\"\n",
    "            )\n",
    "\n",
    "        # Apply transformation for fresh cycle\n",
    "        X[\"Total embryos thawed\"] = X[\"Total embryos thawed\"].astype(str)\n",
    "        X.loc[\n",
    "            (X[\"Fresh cycle\"] == 1) & (X[\"Total embryos thawed\"] == \"0\"),\n",
    "            \"Total embryos thawed\",\n",
    "        ] = \"0 - fresh cycle\"\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "class DropRowsWith999(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer to drop rows with the value \"999\" in any column.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        # Drop rows where any column has the value \"999\"\n",
    "        X_filtered = X[(X != \"999\").all(axis=1)]\n",
    "        \n",
    "        return X_filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.selection import DropFeatures, SmartCorrelatedSelection\n",
    "from feature_engine.imputation import ArbitraryNumberImputer, DropMissingData\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "\n",
    "# Columns to drop\n",
    "columns_to_drop = [\n",
    "    \"Total number of previous DI cycles\",\n",
    "    \"Main reason for producing embroys storing eggs\",\n",
    "    \"Type of treatment - IVF or DI\",\n",
    "    \"Donated embryo\",\n",
    "    \"Eggs thawed (0/1)\",\n",
    "    \"Year of treatment\",\n",
    "    \"Number of live births\",\n",
    "    \"Embryos stored for use by patient\",\n",
    "    \"Fresh eggs stored (0/1)\",\n",
    "    \"Heart three birth congenital abnormalities\",\n",
    "    \"Heart two birth congenital abnormalities\",\n",
    "    \"Heart three delivery date\",\n",
    "    \"Heart three sex\",\n",
    "    \"Heart three birth weight\",\n",
    "    \"Heart three weeks gestation\",\n",
    "    \"Heart three birth outcome\",\n",
    "    \"Heart one birth congenital abnormalities\",\n",
    "    \"Heart two birth weight\",\n",
    "    \"Heart two delivery date\",\n",
    "    \"Heart two sex\",\n",
    "    \"Heart two weeks gestation\",\n",
    "    \"Heart two birth outcome\",\n",
    "    \"Heart one birth weight\",\n",
    "    \"Heart one weeks gestation\",\n",
    "    \"Heart one delivery date\",\n",
    "    \"Heart one sex\",\n",
    "    \"Heart one birth outcome\",\n",
    "    \"Number of foetal sacs with fetal pulsation\",\n",
    "    \"Early outcome\",\n",
    "    \"Partner Type\",\n",
    "]\n",
    "\n",
    "# Columns to be updated with the type of cycle\n",
    "columns_to_update = [\n",
    "    \"Fresh eggs collected\",\n",
    "    \"Total eggs mixed\",\n",
    "    \"Total embryos created\",\n",
    "]\n",
    "\n",
    "\n",
    "def PipelineDataCleaningAndFeatureEngineering():\n",
    "    pipeline_base = Pipeline(\n",
    "        [\n",
    "            # Data Cleaning Steps\n",
    "            (\"filter_ivf\", FilterIVFTreatments()),\n",
    "            (\"drop_erroneous\", DropErroneousEntries()),\n",
    "            (\"drop_columns\", DropFeatures(features_to_drop=columns_to_drop)),\n",
    "            (\n",
    "                \"convert_to_numeric\",\n",
    "                ConvertToNumeric(\n",
    "                    columns=[\n",
    "                        \"Total number of previous pregnancies - IVF and DI\",\n",
    "                        \"Total number of previous live births - IVF or DI\",\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            (\n",
    "                \"zeros_imputer\",\n",
    "                ArbitraryNumberImputer(\n",
    "                    arbitrary_number=0,\n",
    "                    variables=[\n",
    "                        \"Total number of previous pregnancies - IVF and DI\",\n",
    "                        \"Total number of previous live births - IVF or DI\",\n",
    "                    ],\n",
    "                ),\n",
    "            ),\n",
    "            (\n",
    "                \"convert_to_int\",\n",
    "                ConvertToIntegers(\n",
    "                    columns=[\n",
    "                        \"Total number of previous pregnancies - IVF and DI\",\n",
    "                        \"Total number of previous live births - IVF or DI\",\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            (\"fill_sperm_source\", FillSpermSource()),\n",
    "            (\"dot_to_int_999\", ConvertToIntAndReplace999()),\n",
    "            (\"replace_missing_values\", ReplaceMissingValues()),\n",
    "            (\"append_cycle_type\", AppendCycleType()),\n",
    "            (\"micro_injected\", MicroInjectedEmbryos()),\n",
    "            (\"donor_age\", DonorAgeImputer()),\n",
    "            (\"float_to_int\", FloatToIntTransformer()),\n",
    "            (\"e_flagging\", EFlaggingTransformer()),\n",
    "            (\"type_of_cycle\", TypeOfCycleAppender(columns_to_update=columns_to_update)),\n",
    "            (\"drop_999\", DropRowsWith999()),\n",
    "            (\"drop_missing_data\", DropMissingData()),\n",
    "\n",
    "            # Feature Engineering Steps\n",
    "            (\n",
    "                \"one_hot_encoding\",\n",
    "                OneHotEncoder(\n",
    "                    drop_last=True,\n",
    "                    variables=[\n",
    "                        \"Patient age at treatment\",\n",
    "                        \"Total number of previous IVF cycles\",\n",
    "                        \"Patient/Egg provider age\",\n",
    "                        \"Partner/Sperm provider age\",\n",
    "                        \"Specific treatment type\",\n",
    "                        \"Egg source\",\n",
    "                        \"Sperm source\",\n",
    "                        \"Patient ethnicity\",\n",
    "                        \"Partner ethnicity\",\n",
    "                        \"Fresh eggs collected\",\n",
    "                        \"Total eggs mixed\",\n",
    "                        \"Total embryos created\",\n",
    "                        \"Embryos transferred\",\n",
    "                        \"Total embryos thawed\",\n",
    "                        \"Date of embryo transfer\",\n",
    "                    ],\n",
    "                ),\n",
    "            ),\n",
    "            \n",
    "            (\n",
    "                \"smart_correlation\",\n",
    "                SmartCorrelatedSelection(\n",
    "                    method=\"spearman\", threshold=0.9\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipeline_base\n",
    "\n",
    "\n",
    "PipelineDataCleaningAndFeatureEngineering()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Sequential model (Deep Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    # Do not drop the target column here because it is needed for the pipeline\n",
    "    df,\n",
    "    df[\"Live birth occurrence\"],\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the data cleaning and feature engineering pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_data_cleaning_feat_eng = PipelineDataCleaningAndFeatureEngineering()\n",
    "X_train = pipeline_data_cleaning_feat_eng.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realign y_train indices with the transformed X_train to keep only the rows present on the dataset after the cleaning step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.loc[X_train.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the pipeline to the test set and realign indices on y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pipeline_data_cleaning_feat_eng.transform(X_test)\n",
    "y_test = y_test.loc[X_test.index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the target column from the processed X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop([\"Live birth occurrence\"], axis=1)\n",
    "X_test = X_test.drop([\"Live birth occurrence\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Train Set Target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(y_train.value_counts())\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "y_train.value_counts().plot(kind=\"bar\", title=\"Train Set Target Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Target Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use SMOTE (Synthetic Minority Oversampling TEchnique) to balance Train Set target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversample = SMOTE(sampling_strategy='minority', random_state=0)\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Train Set Target distribution after resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(y_train.value_counts())\n",
    "\n",
    "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further split Train set to validation and Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create new training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=0\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def pipeline_pre_processing():\n",
    "    pipeline_base = Pipeline([(\"feat_scaling\", StandardScaler())])\n",
    "\n",
    "    return pipeline_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pipeline_pre_processing()\n",
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_val= pipeline.transform(X_val)\n",
    "X_test = pipeline.transform(X_test)\n",
    "\n",
    "X_train[:2,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define early stopping callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=20,\n",
    "    restore_best_weights=True,  \n",
    "    monitor='val_accuracy',\n",
    "    verbose=1, \n",
    "    mode='max' \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "def create_dl_model(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        # First hidden layer with 64 neurons and a dropout rate of 0.50\n",
    "        Dense(64, activation='relu', input_shape=input_shape),\n",
    "        Dropout(0.5),\n",
    "        # Second hidden layer with 32 neurons and a dropout rate of 0.50\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        # Output layer for binary classification\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get input shape from X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_model = create_dl_model(input_shape)\n",
    "dl_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DataFrame(dl_model.history.history)\n",
    "history.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "history[['loss','val_loss']].plot(style='.-')\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "history[['accuracy','val_accuracy']].plot(style='.-')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "def confusion_matrix_and_report(X, y, pipeline, label_map):\n",
    "    prediction = pipeline.predict(X).reshape(-1)\n",
    "    prediction = np.where(prediction < 0.5, 0, 1)\n",
    "\n",
    "    print(\"---  Confusion Matrix  ---\")\n",
    "    print(\n",
    "        pd.DataFrame(\n",
    "            confusion_matrix(y_true=prediction, y_pred=y),\n",
    "            columns=[[\"Actual \" + sub for sub in label_map]],\n",
    "            index=[[\"Prediction \" + sub for sub in label_map]],\n",
    "        )\n",
    "    )\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"---  Classification Report  ---\")\n",
    "    print(classification_report(y, prediction, target_names=label_map), \"\\n\")\n",
    "\n",
    "\n",
    "def clf_performance(\n",
    "    X_train, y_train, X_test, y_test, X_val, y_val, pipeline, label_map\n",
    "):\n",
    "\n",
    "    print(\"#### Train Set #### \\n\")\n",
    "    confusion_matrix_and_report(X_train, y_train, pipeline, label_map)\n",
    "\n",
    "    print(\"#### Validation Set #### \\n\")\n",
    "    confusion_matrix_and_report(X_val, y_val, pipeline, label_map)\n",
    "\n",
    "    print(\"#### Test Set ####\\n\")\n",
    "    confusion_matrix_and_report(X_test, y_test, pipeline, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_performance(X_train, y_train,\n",
    "                X_test,y_test,\n",
    "                X_val, y_val,\n",
    "                dl_model,\n",
    "                label_map= ['No Success', 'Success']\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
