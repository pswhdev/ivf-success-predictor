{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "*   Fit and evaluate a classification model to predict if a treatment will be successful or not.\n",
    "\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* outputs/datasets/collection/FertilityTreatmentData.csv.gz\n",
    "* Instructions from the notebooks 02 and 04 on which variables to use for data cleaning and feature engineering.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Train set (features and target)\n",
    "* Test set (features and target)\n",
    "* Data cleaning and Feature Engineering pipeline\n",
    "* Modeling pipeline\n",
    "* Feature importance plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the working directory from its current folder to its parent folder\n",
    "* Access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the parent of the current directory the new current directory:\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"A new current directory has been set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Open dataset\n",
    "df = pd.read_csv(\"outputs/datasets/collection/FertilityTreatmentData.csv.gz\")\n",
    "        \n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: ML Pipeline with all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ML pipeline for Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Transformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class FilterIVFTreatments(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.query(\n",
    "            \"`Main reason for producing embroys storing eggs` == 'Treatment - IVF'\"\n",
    "        )\n",
    "\n",
    "\n",
    "class ConvertToNumeric(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            # Replace '>3' with 4\n",
    "            X[col] = X[col].replace(\">3\", 4)\n",
    "            # Convert to numeric\n",
    "            X[col] = pd.to_numeric(X[col])\n",
    "        return X\n",
    "\n",
    "\n",
    "class ConvertToIntegers(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            # Replace '>3' with 4 and convert to int\n",
    "            X[col] = X[col].replace(\">3\", 4).astype(float).astype(int)\n",
    "        return X\n",
    "\n",
    "\n",
    "class FillSpermSource(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[\"Sperm source\"] = X.apply(self._fill_sperm_source, axis=1)\n",
    "        return X\n",
    "\n",
    "    def _fill_sperm_source(self, row):\n",
    "        if pd.isna(row[\"Sperm source\"]):\n",
    "            if not pd.isna(row[\"Sperm donor age at registration\"]):\n",
    "                return \"Donor\"\n",
    "            else:\n",
    "                return \"Partner\"\n",
    "        return row[\"Sperm source\"]\n",
    "\n",
    "\n",
    "# Convert float values to integers and handle NaN values\n",
    "class ConvertToIntAndReplace999(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        # Fill NaN with -1 and convert to int\n",
    "        X[\"Date of embryo transfer\"] = (\n",
    "            X[\"Date of embryo transfer\"].fillna(-1).astype(int)\n",
    "        )\n",
    "        # Replace 999 with 0\n",
    "        X[\"Date of embryo transfer\"] = X[\"Date of embryo transfer\"].replace(999, 0)\n",
    "        return X\n",
    "\n",
    "\n",
    "# Replace missing values based on the \"Embryos transferred\" column\n",
    "class ReplaceMissingValues(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[\"Date of embryo transfer\"] = X.apply(self._replace_missing, axis=1)\n",
    "        return X\n",
    "\n",
    "    def _replace_missing(self, row):\n",
    "        value = row[\"Date of embryo transfer\"]\n",
    "        if value == -1 and row[\"Embryos transferred\"] == 0:\n",
    "            return \"NT\"\n",
    "        elif value == -1:\n",
    "            return \"Missing\"\n",
    "        return value\n",
    "\n",
    "\n",
    "# Append strings based on the \"Fresh cycle\" and \"Frozen cycle\" values\n",
    "class AppendCycleType(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[\"Date of embryo transfer\"] = X.apply(self._append_cycle_type, axis=1)\n",
    "        return X\n",
    "\n",
    "    def _append_cycle_type(self, row):\n",
    "        value = row[\"Date of embryo transfer\"]\n",
    "        if value not in [\"NT\", \"Missing\"]:\n",
    "            if row[\"Fresh cycle\"] == 1:\n",
    "                value = f\"{value} - fresh\"\n",
    "            elif row[\"Frozen cycle\"] == 1:\n",
    "                value = f\"{value} - frozen\"\n",
    "            else:\n",
    "                value = f\"{value} - Mixed fresh/frozen\"\n",
    "        return value\n",
    "\n",
    "\n",
    "class MicroInjectedEmbryos(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        # Embryos transferred from eggs micro-injected imputation\n",
    "        missing_micro_injected = X[\n",
    "            \"Embryos transferred from eggs micro-injected\"\n",
    "        ].isna()\n",
    "        ICSI = X[\"Specific treatment type\"].str.contains(\"ICSI\")\n",
    "        # Only replace missing values\n",
    "        X.loc[\n",
    "            missing_micro_injected & ICSI,\n",
    "            \"Embryos transferred from eggs micro-injected\",\n",
    "        ] = X.loc[missing_micro_injected & ICSI, \"Embryos transferred\"]\n",
    "        X.loc[\n",
    "            missing_micro_injected & ~ICSI,\n",
    "            \"Embryos transferred from eggs micro-injected\",\n",
    "        ] = 0\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "class DonorAgeImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        # Mapping from donor age ranges to patient/partner age ranges\n",
    "        self.egg_age_map = {\n",
    "            \"Between 21 and 25\": \"18-34\",\n",
    "            \"Between 26 and 30\": \"18-34\",\n",
    "            \"Between 31 and 35\": \"18-34\",\n",
    "            \">35\": \"38-39\",\n",
    "            \"<= 20\": \"18-34\",\n",
    "        }\n",
    "        self.sperm_age_map = {\n",
    "            \"Between 21 and 25\": \"18-34\",\n",
    "            \"Between 26 and 30\": \"18-34\",\n",
    "            \"Between 31 and 35\": \"18-34\",\n",
    "            \"Between 36 and 40\": \"38-39\",\n",
    "            \"Between 41 and 45\": \"43-44\",\n",
    "            \">45\": \"45-50\",\n",
    "            \"<= 20\": \"18-34\",\n",
    "        }\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        # Egg donor age imputation\n",
    "        X[\"Egg donor age at registration\"] = X[\"Egg donor age at registration\"].map(\n",
    "            self.egg_age_map\n",
    "        )\n",
    "        missing_egg_age = (X[\"Egg donor age at registration\"].isna()) & (\n",
    "            X[\"Egg source\"] == \"Patient\"\n",
    "        )\n",
    "        X.loc[missing_egg_age, \"Egg donor age at registration\"] = X.loc[\n",
    "            missing_egg_age, \"Patient age at treatment\"\n",
    "        ]\n",
    "        X.rename(\n",
    "            columns={\"Egg donor age at registration\": \"Patient/Egg provider age\"},\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "        # Sperm donor age imputation\n",
    "        X[\"Sperm donor age at registration\"] = X[\"Sperm donor age at registration\"].map(\n",
    "            self.sperm_age_map\n",
    "        )\n",
    "        missing_sperm_age = (X[\"Sperm donor age at registration\"].isna()) & (\n",
    "            X[\"Sperm source\"] == \"Partner\"\n",
    "        )\n",
    "        X.loc[missing_sperm_age, \"Sperm donor age at registration\"] = X.loc[\n",
    "            missing_sperm_age, \"Partner age\"\n",
    "        ]\n",
    "        X.rename(\n",
    "            columns={\"Sperm donor age at registration\": \"Partner/Sperm provider age\"},\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "        # Ensure no duplicate columns\n",
    "        if X.columns.duplicated().any():\n",
    "            raise ValueError(\"Duplicate column names found after transformation\")\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "class FloatToIntTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.float_vars = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Identify float columns\n",
    "        self.float_vars = X.select_dtypes(include=\"float\").columns.tolist()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for var in self.float_vars:\n",
    "            X[var] = X[var].astype(int)\n",
    "        return X\n",
    "\n",
    "\n",
    "class EFlaggingTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        X[\"Embryos transferred\"] = X.apply(self.append_e, axis=1)\n",
    "        return X\n",
    "\n",
    "    def append_e(self, row):\n",
    "        if (\n",
    "            row[\"Embryos transferred\"] == 1\n",
    "            and row[\"Elective single embryo transfer\"] == 1\n",
    "        ):\n",
    "            return \"1e\"\n",
    "        else:\n",
    "            return row[\"Embryos transferred\"]\n",
    "\n",
    "\n",
    "class TypeOfCycleAppender(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_update):\n",
    "        self.columns_to_update = columns_to_update\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        # Ensure columns have the correct data type to avoid issues\n",
    "        for column in self.columns_to_update:\n",
    "            X[column] = X[column].astype(str)\n",
    "\n",
    "        # Apply transformation for frozen cycle\n",
    "        for column in self.columns_to_update:\n",
    "            X.loc[(X[\"Frozen cycle\"] == 1) & (X[column] == \"0\"), column] = (\n",
    "                \"0 - frozen cycle\"\n",
    "            )\n",
    "\n",
    "        # Apply transformation for fresh cycle\n",
    "        X[\"Total embryos thawed\"] = X[\"Total embryos thawed\"].astype(str)\n",
    "        X.loc[\n",
    "            (X[\"Fresh cycle\"] == 1) & (X[\"Total embryos thawed\"] == \"0\"),\n",
    "            \"Total embryos thawed\",\n",
    "        ] = \"0 - fresh cycle\"\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.selection import DropFeatures, SmartCorrelatedSelection\n",
    "from feature_engine.imputation import ArbitraryNumberImputer, DropMissingData\n",
    "from feature_engine.encoding import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "# Columns to drop\n",
    "columns_to_drop = [\n",
    "    \"Main reason for producing embroys storing eggs\",\n",
    "    \"Type of treatment - IVF or DI\",\n",
    "    \"Donated embryo\",\n",
    "    \"Eggs thawed (0/1)\",\n",
    "    \"Year of treatment\",\n",
    "    \"Number of live births\",\n",
    "    \"Embryos stored for use by patient\",\n",
    "    \"Fresh eggs stored (0/1)\",\n",
    "    \"Heart three birth congenital abnormalities\",\n",
    "    \"Heart two birth congenital abnormalities\",\n",
    "    \"Heart three delivery date\",\n",
    "    \"Heart three sex\",\n",
    "    \"Heart three birth weight\",\n",
    "    \"Heart three weeks gestation\",\n",
    "    \"Heart three birth outcome\",\n",
    "    \"Heart one birth congenital abnormalities\",\n",
    "    \"Heart two birth weight\",\n",
    "    \"Heart two delivery date\",\n",
    "    \"Heart two sex\",\n",
    "    \"Heart two weeks gestation\",\n",
    "    \"Heart two birth outcome\",\n",
    "    \"Heart one birth weight\",\n",
    "    \"Heart one weeks gestation\",\n",
    "    \"Heart one delivery date\",\n",
    "    \"Heart one sex\",\n",
    "    \"Heart one birth outcome\",\n",
    "    \"Number of foetal sacs with fetal pulsation\",\n",
    "    \"Early outcome\",\n",
    "    \"Partner Type\",\n",
    "]\n",
    "\n",
    "# Columns to be updated with the type of cycle\n",
    "columns_to_update = [\n",
    "    \"Fresh eggs collected\",\n",
    "    \"Total eggs mixed\",\n",
    "    \"Total embryos created\",\n",
    "]\n",
    "\n",
    "def PipelineDataCleaningAndFeatureEngineering():\n",
    "    pipeline_base = Pipeline(\n",
    "        [\n",
    "            # Data Cleaning Steps\n",
    "            (\"filter_ivf\", FilterIVFTreatments()), \n",
    "            (\"drop_columns\", DropFeatures(features_to_drop=columns_to_drop)),\n",
    "            (\n",
    "                \"convert_to_numeric\",\n",
    "                ConvertToNumeric(\n",
    "                    columns=[\n",
    "                        \"Total number of previous pregnancies - IVF and DI\",\n",
    "                        \"Total number of previous live births - IVF or DI\",\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            (\n",
    "                \"zeros_imputer\",\n",
    "                ArbitraryNumberImputer(\n",
    "                    arbitrary_number=0,\n",
    "                    variables=[\n",
    "                        \"Total number of previous pregnancies - IVF and DI\",\n",
    "                        \"Total number of previous live births - IVF or DI\",\n",
    "                    ],\n",
    "                ),\n",
    "            ),\n",
    "            (\n",
    "                \"convert_to_int\",\n",
    "                ConvertToIntegers(\n",
    "                    columns=[\n",
    "                        \"Total number of previous pregnancies - IVF and DI\",\n",
    "                        \"Total number of previous live births - IVF or DI\",\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            (\"fill_sperm_source\", FillSpermSource()),  \n",
    "            (\"dot_to_int_999\", ConvertToIntAndReplace999()),  \n",
    "            (\"replace_missing_values\", ReplaceMissingValues()),  \n",
    "            (\"append_cycle_type\", AppendCycleType()),  \n",
    "            (\"micro_injected\", MicroInjectedEmbryos()),  \n",
    "            (\"donor_age\", DonorAgeImputer()),  \n",
    "            (\"float_to_int\", FloatToIntTransformer()),  \n",
    "            (\"e_flagging\", EFlaggingTransformer()),  \n",
    "            (\"type_of_cycle\", TypeOfCycleAppender(columns_to_update=columns_to_update)),\n",
    "            (\"drop_missing_data\", DropMissingData()),\n",
    "\n",
    "            # Feature Engineering Steps\n",
    "            (\n",
    "                \"ordinal_encoding\",\n",
    "                OrdinalEncoder(\n",
    "                    encoding_method='arbitrary',\n",
    "                    variables=[\n",
    "                        \"Patient age at treatment\",\n",
    "                        \"Partner/Sperm provider age\",\n",
    "                        \"Patient/Egg provider age\",\n",
    "                        \"Total number of previous IVF cycles\",\n",
    "                        \"Total number of previous DI cycles\",\n",
    "                        \"Fresh eggs collected\",\n",
    "                        \"Total eggs mixed\",\n",
    "                        \"Total embryos created\",\n",
    "                        \"Embryos transferred\",\n",
    "                        \"Total embryos thawed\",\n",
    "                        \"Date of embryo transfer\",\n",
    "                        \"Partner age\"\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            (\n",
    "                \"one_hot_encoding\",\n",
    "                OneHotEncoder(\n",
    "                    variables=[\n",
    "                        \"Specific treatment type\",\n",
    "                        \"Egg source\",\n",
    "                        \"Sperm source\",\n",
    "                        \"Patient ethnicity\",\n",
    "                        \"Partner ethnicity\",\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            (\"smart_correlation\", SmartCorrelatedSelection()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipeline_base\n",
    "\n",
    "PipelineDataCleaningAndFeatureEngineering()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Pipeline for Modelling and Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feat Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Feat Selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# ML algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "def PipelineClf(model):\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"feat_selection\", SelectFromModel(model)),\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "\n",
    "    return pipeline_base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Class for Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "class HyperparameterOptimizationSearch:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "\n",
    "            model = PipelineClf(self.models[key])\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, )\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "        columns = ['estimator', 'min_score',\n",
    "                   'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "        return df[columns], self.grid_searches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['Live birth occurrence'], axis=1),\n",
    "    df['Live birth occurrence'],\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Target Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the data cleaning and feature engineering pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_data_cleaning_feat_eng = PipelineDataCleaningAndFeatureEngineering()\n",
    "X_train = pipeline_data_cleaning_feat_eng.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realign y_train indices with the transformed X_train to keep only the rows present on the dataset after the cleaning step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.loc[X_train.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the pipeline to the test set and realign indices on y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pipeline_data_cleaning_feat_eng.transform(X_test)\n",
    "y_test = y_test.loc[X_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Train Set Target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use SMOTE (Synthetic Minority Oversampling TEchnique) to balance Train Set target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversample = SMOTE(sampling_strategy='minority', random_state=0)\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Train Set Target distribution after resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search CV - Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use standard hyperparameters to find most suitable algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_quick_search = {\n",
    "    \"LogisticRegression\": LogisticRegression(random_state=0),\n",
    "    \"XGBClassifier\": XGBClassifier(random_state=0),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=0),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(random_state=0),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=0),\n",
    "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=0),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=0),\n",
    "}\n",
    "\n",
    "params_quick_search = {\n",
    "    \"LogisticRegression\": {},\n",
    "    \"XGBClassifier\": {},\n",
    "    \"DecisionTreeClassifier\": {},\n",
    "    \"RandomForestClassifier\": {},\n",
    "    \"GradientBoostingClassifier\": {},\n",
    "    \"ExtraTreesClassifier\": {},\n",
    "    \"AdaBoostClassifier\": {},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick GridSearch CV - Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, recall_score\n",
    "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
    "search.fit(X_train, y_train,\n",
    "           scoring =  make_scorer(recall_score, pos_label=1),\n",
    "           n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
